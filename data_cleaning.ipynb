{"cells":[{"cell_type":"markdown","metadata":{"id":"wfySDNJdj7Mh"},"source":["DATA CLEANING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mVljdVltj7Ml"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","path = '/Users/banna/Desktop/CEE 4803/HW/HW2/1989-2019 FDOT Pavement Data.csv'\n","df = pd.read_csv(path)"]},{"cell_type":"markdown","metadata":{"id":"X97py_iqj7Mn"},"source":["Rows with the following stand to be deleted.\n","    \n","> A single empty value within their repair cycle designated on that row OR\n","\n","> Any instance of a later quality rating greater than a previous quality rating within the repair cycle OR\n","\n","> Any instance of a quality rating of 0 OR\n","\n","> Any instance of a zero or NaN in any row of the predictor columns.\n","    \n","> Any instance of a duplicate row."]},{"cell_type":"markdown","metadata":{"id":"dCaRhO4qj7Mn"},"source":["CLEAN CRACK DATA WITH LOCATION AND PREDICTOR DATA IN THE LEFT COLUMNS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6n6rRQ_1j7Mn","outputId":"ef96048f-ec2c-4539-ee60-7876bbbd4b88"},"outputs":[{"name":"stdout","output_type":"stream","text":["Before the selection criteria were applied, there were 14388 rows.\n","After the selection criteria were applied, there are 13625 rows.\n","That means that we retained 94.70% of the data.\n"]}],"source":["# Define columns to drop\n","columns_to_drop = ['DISTRICT', 'RCILM', 'SYSTEM', 'TYPE', 'SURFTYPE', 'DEFREAS']\n","df = df.drop(columns=columns_to_drop)\n","\n","# Define columns of interest\n","crk_years = [str(year) for year in range(1989, 2020)]\n","crk_columns = [f'CRK{year}' for year in crk_years]\n","\n","# Extract columns related to ratings and predictors\n","df_id = df.loc[:, 'RDWYID':'EMP']\n","df_predictors = df.loc[:, 'MAXSPEED':'FC']\n","df_cycle = df.loc[:, 'cyclastyr':'cycdefage']\n","\n","df_ratings = df.loc[:, crk_columns]\n","df_rut = df.loc[:, 'RUT1989':'RUT2019']\n","df_ride = df.loc[:, 'RIDE1989':'RIDE2019']\n","df_pcr = df.loc[:, 'PCR1989':'PCR2019']\n","\n","# Combine relevant data into a single DataFrame\n","df_combined = pd.concat([df_id, df_cycle, df_predictors, df_ratings], axis=1)\n","df_crk = df_combined.loc[:, crk_columns]\n","selected_rows = [] # Initialize a list to store rows that meet criteria\n","\n","# Iterate through the DataFrame to apply selection criteria\n","for index, row in df_crk.iterrows():\n","    condition = []\n","    cyc_new_year = df.loc[index, 'cycnewyr']\n","    cyc_last_year = df.loc[index, 'cyclastyr']\n","    age_vector = []\n","    quality_vector = []\n","    i = 0\n","\n","    for col in df_crk.columns:\n","        year = int(col[3:])\n","        col_name = col\n","\n","        if (year >= cyc_new_year) and (year <= cyc_last_year):\n","            age_vector.append(i)\n","            i += 1\n","            quality = df_crk.loc[index, col]\n","\n","            if pd.notna(quality):\n","                quality_vector.append(quality)\n","            else:\n","                condition.append(False)\n","\n","        if len(quality_vector) < len(age_vector):\n","            condition.append(False)\n","\n","        for n in range(1, len(quality_vector)):\n","            if quality_vector[n] > quality_vector[n - 1]:\n","                condition.append(False)\n","\n","        if 0 in quality_vector:\n","            condition.append(False)\n","\n","    result = all(condition)\n","    selected_rows.append(result)\n","\n","df_selected = df_combined[selected_rows] # Create a new DataFrame with selected rows\n","predictor_columns = ['cycage', 'MAXSPEED', 'ESALS'] # Define predictor columns\n","\n","# Filter rows with NaNs or 0s in predictor columns\n","df_selected = df_selected.dropna(subset=predictor_columns)\n","df_selected = df_selected[df_selected[predictor_columns].ne(0).all(axis=1)]\n","\n","df_selected = df_selected.drop_duplicates() # Remove duplicate rows\n","# df_selected.to_csv(\"cleanedPredictorsAndRatings.csv\", index=False) # Save the cleaned DataFrame to a CSV file\n","\n","# Calculate and print the percentage of retained data\n","unclean_length = len(pd.read_csv(file_path))\n","clean_length = len(df_selected)\n","percentage_retained = (clean_length / unclean_length) * 100\n","\n","print(f'Before the selection criteria were applied, there were {unclean_length} rows.')\n","print(f'After the selection criteria were applied, there are {clean_length} rows.')\n","print(f'That means that we retained {percentage_retained:.2f}% of the data.')"]}],"metadata":{"kernelspec":{"display_name":"DA","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}